---
title: "Homework 2"
subtitle: "BIOS 635"
author: "Alexis Payton"
date: "1/28/2021"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, include=TRUE,
                      fig.width = 10, fig.height = 5)
```

```{r packages, echo=TRUE}
library(tidyverse)
library(broom)
library(gtsummary)
library(flextable)
library(gt)
library(caret)
library(GGally)
```

# Introduction
In this assignment you will practice using some basic machine learning methods and concepts discussed so far in lecture to develop prediction algorithms from real-world public health datasets.  You will predict a continuous outcome first, followed by a binary outcome ("Yes" or "No), using K-nearest neighbor, linear regression, and logistic regression

# 1
## Setup
In the first part, you will work with cancer mortality data in the United States at the county level from 2010-2016, with demographic information on the counties from 2013 US Census estimates.

The outcome of interest in the data is mean yearly per capita (100,000 people) cancer mortalities from 2010-2016, denoted `TARGET_deathRate` in the dataset (`cancer_reg.csv`).  So more info on the dataset in the docs folder.  

## A
First, let's look at summary statistics of the variables of interest in the data using the function `tbl_summary` in the `gtsummary` package.  Be sure to print the table as a `flextable` using the function `as_flex_table`.  Specifically:

- First, create variable `deathrate_vs_median` in dataset after reading in CSV
  - `deathrate_vs_median`="No" if `TARGET_deathRate`< `median(TARGET_deathRate)`
  - ="Yes" otherwise
- Provide stats for the following variables:
  -`TARGET_deathRate`, `medIncome`, `povertyPercent`, `MedianAge`, `PctPrivateCoverage`, `PctPublicCoverage`, `PctWhite`, `PctBlack`, `PctAsian`, `PctOtherRace`
  - **NOTE**: Don't remove variables from dataset to only those marked above.  Only use functions in `gtsummary` to remove variables from table (see `include` argument)
  - Group the summary statistics by `deathrate_vs_median`
  - Include sample size $N$ using `add_n`
  - Add p-values from one-way ANOVA test for differences in variables between "No" and "Yes" groups of `TARGET_deathRate`
  - For all variables, provide mean and standard deviation (SD) as statistics
  - Add a gray background to the cells in the row corresponding to `TARGET_deathRate`
    - **Hint**: Look at changing row/column background color in `flextable` package after using
    `as_flex_table` function
  - Also, bold text in header row after using `as_flex_table`

```{r 1a}
#setting working directory
setwd('/Users/alexis/Documents/BIOS 635/Assignment 2/data')

#reading in data
cancer_df = read_csv('cancer_reg.csv')
diabetes_df = read_csv('diabetes.csv') 

#creating a col to see if the cancer death rate for each county is greater than the median
cancer_df = cancer_df %>% 
  mutate(deathrate_vs_median = ifelse(TARGET_deathRate < median(TARGET_deathRate) ,'No', 'Yes')) #no = GOOD!, yes = BAD!
  
#making flextable
ft = cancer_df %>%
  group_by(deathrate_vs_median) %>%
  #selecting columns of interest
  select("TARGET_deathRate", "medIncome", "povertyPercent", "MedianAge", "PctPrivateCoverage", "PctPublicCoverage",  "PctWhite", "PctBlack", "PctAsian", "PctOtherRace") %>% #IS THIS THE RIGHT FUNCTION!!!?
  tbl_summary(by = deathrate_vs_median, missing = "no", statistic = list(all_continuous() ~ "{mean} ({sd})")) %>%
  #add_n() %>% WE DON'T NEED THIS FOR SAMPLE SIZE???
  add_p() %>% #adding p value from wilcoxon rank sum
  as_flex_table() 

ft = bg(ft, bg = "gray", i = 1) #making the first row gray
ft = bold(ft, part = "header") #bolding header
ft
```

## B
Now, let's do some data visualization.  

Let's look at some 2-dimensional scatterplots of some of the above variables to assess correlation.  Specifically, recreate the following matrix of scatterplots:

- Look at the following variables
  - Use `ggpairs` from the `GGally` package:     
    - https://www.r-graph-gallery.com/199-correlation-matrix-with-ggally.html
  - `medIncome`, `povertyPercent`, `PctPrivateCoverage`, `PctPublicCoverage`
  - Color points by `deathrate_vs_median`
  - Provide some interpretation of the relationships you see in the figure.  Specifically:
    - Are there variables that have high correlations?
      - Do these high correlations make sense conceptually?
    - Compare the distributions of the variables between the two mortality rate groups (see diagonal).

<b> Answer </b>
Based on what I've learned from my first biostatistics class, we consider anything with a correlation coefficent > 0.7 to be highly correlated. In the plot below, that includes the following correlations:
- Overall
  - Poverty & Median Income
  - Private Coverage & Median Income
  - Public Coverage & Median Income
  - Private Coverage & Poverty
  - Public Coverage & Private Coverage
- Below Median Mean per capita Cancer Mortality (encoded as "Yes")
  - Poverty & Median Income
  - Private Coverage & Median Income
  - Public Coverage & Median Income
  - Private Coverage & Poverty
  - Public Coverage & Private Coverage
- Above Median Mean per capita Cancer Mortality (encoded as "No")
  - Poverty & Median Income
  - Public Coverage & Median Income
  - Private Coverage & Poverty
  
  
These correlations make sense conceptually, because higher paying jobs tend to have better private healthcare options and coverage. The diagonal represents the distribution of each variable stratified by "deathrate_vs_median". So, overall we can see that counties with a mean per capita cancer mortality greater than the median for all counties have higher rates of poverty and goverment-provided healthcare, while having lower rates of median income and private healthcare. 

```{r 1b}
ggpairs(cancer_df%>%
  #slecting all the data needed for the plots
  select(medIncome, povertyPercent, PctPrivateCoverage, PctPublicCoverage, deathrate_vs_median), 
        #only choosing first 4 columns to display
        columns = 1:4,
        #color by deathrate_vs_median
        ggplot2::aes(color = deathrate_vs_median),
        columnLabels = c("Median Income", "Poverty (%)", "Private Coverage (%)", "Public Coverage (%)"))
```

## C
Now, let's begin to create our prediction algorithms for `TARGET_deathRate`.  First, we will start with using K-nearest neighbor (KNN).

Let's consider the features included in our summary statistics table (`TARGET_deathRate`, `medIncome`, `povertyPercent`, `MedianAge`, `PctPrivateCoverage`, `PctPublicCoverage`, `PctWhite`, `PctBlack`, `PctAsian`, `PctOtherRace`).  

- First, we will split our data into separate training and testing sets (60% in training and 40% in testing) randomly.  
- Next, train a KNN algorithm on the training dataset.
  - Use `train` function in `caret` function (see lecture slides).  Use `tuneLength`=20 and center and scale the features (see `preProcess` argument).
  - Leave everything else at default.  What is the "best" tuning parameter value chosen for parameter $k$?
  What criteria is used by R to select this "best" parameter?
  - Plot the RMSE for each considered value of $k$ during the tuning process.  What does $k$ represent based on the plot (**Hint**: see lecture slides and x-axis of plot)
- Lastly, test your algorthim at this "best" tuning parameter value on the test set.  Print out the test set performance based on RMSE, $R^2$, and MAE using `flextable`

<b> Answer </b>
The best tuning parameter is k = 43 and the lowest root mean squared error is used to find the best tuning parameter. Based on the plot, k is the number of nearest neighbors.  

```{r 1c}
set.seed(12) # Setting seed for reproducibility

#only including variables of interest
cancer_small_df = cancer_df %>%
  select("TARGET_deathRate", "medIncome", "povertyPercent", "MedianAge", "PctPrivateCoverage", "PctPublicCoverage",  "PctWhite", "PctBlack", "PctAsian", "PctOtherRace")
#splitting data into training and testing sets
cancer_df_index = createDataPartition(cancer_small_df$TARGET_deathRate, p = 0.6, list = FALSE)
cancer_train = cancer_small_df[cancer_df_index,]
cancer_test = cancer_small_df[-cancer_df_index,]

#training algorithm 
knn_cancer= train(TARGET_deathRate ~ ., data = cancer_train, method = 'knn', tuneLength = 20)
knn_cancer

#plotting 
plot(knn_cancer)

#testing algorithm
knn_pred_deathrate = predict(knn_cancer, newdata = cancer_test)
diff = knn_pred_deathrate -cancer_test$TARGET_deathRate

#first making empty df for values to go into 
table = data.frame(array(0, dim = c(1,3))) #making array with zeros
colnames(table) = c("Root Mean Square Error", "R^2", "Mean Absolute Error")
table$`Root Mean Square Error` = round(sqrt(mean((diff)^2)), 7)
table$`$R^2$` = 1 - (sum((diff)^2) / sum((cancer_test$TARGET_deathRate - mean(cancer_test$TARGET_deathRate))^2))
table$`Mean Absolute Error` = mean(abs(diff))

#making table
table %>%
  flextable()

```

## D
### I
Let's next move to a linear regression model for prediction.  We consider the same features listed in 1c with the same outcome variable.

- Use the same training and testing sets created in 1c
- Train a linear regression algorithm with all of the above features.  Print out the following results:
  - Coefficient estimate table from `summary` function (estimate, standard error, test statistic, p-value)
    - Create this table using the `tidy` function from `broom` and print out using `flextable`
  - Evaluate the following assumptions using the corresponding visual
    - 1. Homoskedasicity (fitted value by residual plot)
    - 2. Normality (QQ plot of residuals vs theoretical normal distribution)
  - One may argue that normally distributed residuals are not a concern for this dataset.  Why?
  - One common belief in regression is that your **outcome** is assumed to be normally distributed.  Why is
  this incorrect?
  
<b> Answer </b>
A linear regression assumes that homoscedasticity, independent residuals, and normally distributed residuals or the large sample approximation is being met. Since the Scale-Location plot isn't a horizontal line with equally spread points, we can't assume homoscedasticity for this dataset. Since the Q-Q plot follow the dashed line reasonably well, we can assume the residuals are normally distributed.
```{r 1d}
#linear regression algorithm
lm_train = lm(formula = TARGET_deathRate~medIncome+povertyPercent+ MedianAge+ PctPrivateCoverage+ PctPublicCoverage+PctWhite+ PctBlack+ PctAsian+ PctOtherRace, data = cancer_train) #INDEPENDENT VARIBALES???

#making table based on the regression
tidy(lm_train) %>%
  mutate(p.value = ifelse(p.value < 0.005, "<0.005",
                          as.character(round(p.value, 2)))) %>%
  flextable()

#testing for homoscedasticity/normality
plot(lm_train)
```
### II
- Test the algorithm developed in the previous step on the test dataset.  Print out the following in a `flextable`
  - Test set RMSE, $R^2$, adjusted $R^2$, and MAE
- In a separate `flextable`, print out these same metrics based on the performance in the training set
  - Evaluate the differences between the training and testing performance
- Based on your plots in 1b, do you have any concerns about collinearity?  If so, how would you change the set of feature variable used to fix this concern?  How did you choose this set?
  - **Note**: you don't need to actually re-run the regression analysis with this reduced set of features
  
<b> Answer </b>
FINISH!!!
```{r 1dII}
#testing algorithm
lm_pred_deathrate = predict(lm_train, newdata = cancer_test)
lm_diff = lm_pred_deathrate -cancer_test$TARGET_deathRate

#first making empty df for values to go into 
lm_table = data.frame(array(0, dim = c(1,3))) #making array with zeros
colnames(lm_table) = c("Root Mean Square Error", "R^2", "Mean Absolute Error")
lm_table$`Root Mean Square Error` = round(sqrt(mean((lm_diff)^2)), 7)
lm_table$`R^2` = 1 - (sum((lm_diff)^2) / sum((cancer_test$TARGET_deathRate - mean(cancer_test$TARGET_deathRate))^2))
lm_table$`Mean Absolute Error` = mean(abs(lm_diff))

#making table
lm_table %>%
  flextable()

```
# 2
## Setup
In the second part, you will work with diabetes incidence data in the US, composed of Native American, female hospital patients at 21 years old.

The outcome of interest, `Outcome` in the data is binary indicator if the patient has a diagnosis of diabetes (0 = "No", 1 = "Yes").  You will try to predict this outcome based on patient traits as features.  See the docs folder for more information.  The dataset is called `diabetes_data.csv`.

## A
First, let's look at summary statistics of the variables of interest in the data using the function `tbl_summary` in the `gtsummary` package.  Be sure to print the table as a `flextable` using the function `as_flex_table`.  Specifically:

- Provide stats for the following variables:
  - `Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `Age`
  - **NOTE**: Don't remove variables from dataset to only those marked above.  Only use functions in `gtsummary` to remove variables from table (see `include` argument)
  - Group the summary statistics by `Outcome`
  - Include sample size $N$ using `add_n`
  - Add p-values from one-way ANOVA test for differences in variables between groups of `Outcome`
  - For all variables, provide mean and standard deviation (SD) as statistics
  - Also, bold text in header row after using `as_flex_table`

```{r 2a}
#making flextable
ft = diabetes_df %>%
  group_by(Outcome) %>%
  #selecting columns of interest
  select(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, Age) %>% #IS THIS THE RIGHT FUNCTION!!!?
  tbl_summary(by = Outcome, missing = "no", statistic = list(all_continuous() ~ "{mean} ({sd})")) %>%
  #add_n() %>% WE DON'T NEED THIS FOR SAMPLE SIZE???
  add_p() %>% #adding p value from wilcoxon rank sum
  as_flex_table() 

ft = bold(ft, part = "header") #bolding header
ft
```

## B
Now, let's begin to create our prediction algorithms for `Outcome`.  First, we will start with using K-nearest neighbor (KNN).

Let's consider the features included in our summary statistics table (`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `Age`).  

- First, we will split our data into separate training and testing sets (60% in training and 40% in testing) randomly.  
- Next, train a KNN algorithm on the training dataset.
  - Use `train` function in `caret` function (see lecture slides).  Use `tuneLength`=20 and center and scale the features (see `preProcess` argument).
  - Leave everything else at default.  What is the "best" tuning parameter value chosen for parameter $k$?
  What criteria is used by R to select this "best" parameter?
  - Plot the Prediction Accuracy for each considered value of $k$ during the tuning process.  What does $k$ represent based on the plot (**Hint**: see lecture slides and x-axis of plot)
- Lastly, test your algorithm at this "best" tuning parameter value on the test set.  Print out the test set performance based on Prediction Accuracy, Sensitivity, Specificity, PPV, and NPV using `flextable`.
  - **Hint**: Use `confusionMatrix` function in `caret` package.  Then convert to data frame to print as
  `flextable`

<b> Answer </b>
The best tuning parameter is k = 29 and the highest accuracy value is used to find the best tuning parameter. Based on the plot, k is the number of nearest neighbors.  
```{r 2b}
set.seed(12) # Setting seed for reproducibility

#only including variables of interest
diabetes_df$Outcome = factor(diabetes_df$Outcome) #need to first convert this to a factor for the train function to work
diabetes_small_df = diabetes_df %>%
  select(Outcome, Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, Age)

#splitting data into training and testing sets
diabetes_df_index = createDataPartition(diabetes_small_df$Outcome, p = 0.6, list = FALSE)
diabetes_train = diabetes_small_df[diabetes_df_index,]
diabetes_test = diabetes_small_df[-diabetes_df_index,]

#training algorithm 
#ctrl <- trainControl(method="repeatedcv",repeats = 3)
knn_diabetes = train(Outcome ~ ., data = diabetes_train, method = 'knn', tuneLength = 20, preProcess = c("center","scale"))
#knn_diabetes

#plotting 
#plot(knn_diabetes)

# testing algorithm and making flextable
matrix = confusionMatrix(predict(knn_diabetes, newdata = diabetes_test), diabetes_test$Outcome)
ft = data.frame(t(c(matrix$overall[1], matrix$byClass[1:4]))) %>% #extracting accuracy, sens, spec, PPV, NPV
  flextable()
ft
```

## C
Finally, we will end with using logistic regression.  We consider the same features listed in 2b with the same outcome variable.

- Train a logistic regression algorithm with all of the above features.  Print out the following results:
  - Coefficient estimate table from `summary` function (estimate, standard error, test statistic, p-value)
    - Create this table using the `tidy` function from `broom` and print out using `flextable`
  - Print out the test set performance based on Prediction Accuracy, Sensitivity, Specificity, PPV, and NPV using `flextable`.
    - **Hint**: Use `confusionMatrix` function in `caret` package.  Then convert to data frame to print as
  `flextable`

```{r 2c}
set.seed(12) # Setting seed for reproducibility

```
